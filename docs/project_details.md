# Power Plant Energy Output Prediction Project

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

---

## English

**Author**: Lily Wang  
**Project Type**: AI Product Management / Machine Learning  
**Algorithms**: Linear Regression, Random Forest Regressor  

---

### 1. Project Objective

The goal of this project is to predict the net hourly electrical energy output (PE) of a Combined Cycle Power Plant. Accurate predictions are practically important for optimizing plant operations, energy scheduling, and maintenance planning.

The project focuses on four main aspects:

1. Modeling Approach
2. Model Building
3. Model Evaluation
4. Model Interpretation

---

### 2. Modeling Approach

#### 2.1 Problem Type

- **Target Variable**: PE (Net Hourly Electrical Energy Output), measured in MW (MegaWatt)  
- **Value Range**: 420.26 â€“ 495.76 MW  
- **Problem Type**: Regression (predicting continuous numerical values)

ğŸ“Š **[Visualization Placeholder]**: Dataset preview showing PE column and value ranges  
_Source: `notebooks/power_plant_prediction_en.ipynb`_

#### 2.2 Feature Selection

Four environmental sensor features were used:

| Feature | Description | Range | Correlation with PE |
|---------|------------|-------|------------------|
| AT | Ambient Temperature | 1.81 â€“ 37.11 Â°C | -0.948 (strong negative) |
| V | Exhaust Vacuum | 25.36 â€“ 81.56 cm Hg | -0.870 (strong negative) |
| AP | Ambient Pressure | 992.89 â€“ 1033.30 millibar | +0.518 (moderate positive) |
| RH | Relative Humidity | 25.56% â€“ 100.16% | +0.390 (weak positive) |

**Rationale for Feature Selection**:

1. Physical significance: Each feature affects power output based on thermodynamics.  
2. Significant correlation with target variable.  
3. High-quality data: 9568 records, no missing or duplicate values.

ğŸ“Š **[Visualization Placeholder]**: Feature correlation matrix or heatmap  
_Source: `notebooks/power_plant_prediction_en.ipynb`_

#### 2.3 Algorithm Selection

Two algorithms were compared:

1. **Linear Regression**  
   - Parametric, assumes linear relationships  
   - Simple, fast, interpretable  
   - Used as baseline model

2. **Random Forest Regressor**  
   - Non-parametric ensemble algorithm (multiple decision trees)  
   - Captures non-linear relationships and feature interactions  
   - No assumption on data distribution

---

### 3. Model Building

#### 3.1 Data Splitting Strategy

- **Dataset size**: 9568 records  
- **Initial split**: 80% training (~7654), 20% testing (~1914)  
- **Principle**: Test set reserved for final evaluation to prevent bias

ğŸ“Š **[Visualization Placeholder]**: Data splitting diagram (80/20 + 5-Fold CV illustration)  
_Source: `docs/presentation_script.md` or custom diagram_

#### 3.2 Cross-Validation

- **Method**: 5-Fold Cross-Validation on training set  
- **Purpose**:  
  - Maximize data usage  
  - Obtain robust evaluation  
  - Reduce overfitting risk

#### 3.3 Model Comparison

- **Evaluation Metric**: MAE (Mean Absolute Error)  
- **Scikit-learn note**: `cross_val_score` uses neg_mean_absolute_error to align "higher is better" convention

**5-Fold CV Results**:

| Model | Avg MAE | Std Dev | 5-Fold Range |
|-------|---------|---------|-------------|
| Linear Regression | 3.63 MW | Â±0.06 | 3.56â€“3.71 MW |
| Random Forest | 2.48 MW | Â±0.07 | 2.35â€“2.55 MW |

**Observation**: Random Forest reduces error by 31.68% and shows stable performance.

ğŸ“Š **[Visualization Placeholder]**: Bar chart comparing CV MAE of both models with error bars  
_Source: `notebooks/power_plant_prediction_en.ipynb`_

---

### 4. Model Evaluation

#### 4.1 Evaluation Metrics

| Metric | MAE | RÂ² |
|--------|-----|----|
| Meaning | Average prediction error | Variance explained by model |
| Unit | MW | Unitless (0-1) |
| Goal | Lower is better | Higher is better |
| Example | 2.33 MW avg error | RÂ² = 0.96 |

- MAE chosen for interpretability, robustness to outliers, and practical relevance.  
- RÂ² included for standardized comparison.

#### 4.2 Test Set Results

- **Best model**: Random Forest  
- **Test MAE**: 2.33 MW  
- **Test RÂ²**: 0.9637  

**Interpretation**:

1. Average prediction error â‰ˆ 0.5% of output range  
2. Explains 96.37% of power output variance  
3. CV MAE close to test MAE â†’ no overfitting  

**Visualization**: Scatter plot of actual vs predicted values shows most points tightly aligned along y=x line, indicating high accuracy and stability.

ğŸ“Š **[Visualization Placeholder]**: Scatter plot of Actual vs Predicted values on test set  
_Source: `notebooks/power_plant_prediction_en.ipynb`_

---

### 5. Model Interpretation

#### 5.1 Why Random Forest Performs Better

1. Captures non-linear relationships in complex thermodynamic processes  
2. Handles feature interactions (e.g., high temp + high humidity effects)  
3. Ensemble approach averages 100 decision trees to reduce overall error

#### 5.2 Practical Implications

- **Energy Scheduling**: Predict output based on weather forecasts  
- **Operations Optimization**: Detect equipment issues when actual vs predicted differ  
- **Cost Control**: Improve fuel procurement and inventory management

- Test MAE 2.33 MW â†’ practical accuracy achieved

#### 5.3 Overfitting Prevention

- Independent test set  
- 5-Fold CV ensures robust performance  
- Consistent MAE between CV and test set confirms generalization

---

### 6. Future Improvements

1. Explore additional algorithms: Gradient Boosting, Neural Networks  
2. Hyperparameter tuning for Random Forest  
3. Incorporate more features: historical generation data, equipment runtime

---

### 7. Conclusion

This project demonstrates a successful power plant energy prediction model:

- Correct problem identification (regression) and algorithm selection  
- Rigorous validation (5-Fold CV + independent test set)  
- Practical performance (Test MAE 2.33 MW, 0.5% relative error) suitable for real-world energy scheduling and operations optimization

---

## ä¸­æ–‡

**ä½œè€…**: Lily Wang  
**å°ˆæ¡ˆé¡å‹**: AI ç”¢å“ç®¡ç† / æ©Ÿå™¨å­¸ç¿’  
**æ¼”ç®—æ³•**: Linear Regressionã€Random Forest Regressor  

---

### 1. å°ˆæ¡ˆç›®æ¨™

æœ¬å°ˆæ¡ˆæ—¨åœ¨é æ¸¬è¤‡åˆå¾ªç’°ç™¼é›»å» çš„æ·¨é›»åŠ›è¼¸å‡ºï¼ˆPEï¼‰ã€‚æº–ç¢ºçš„é æ¸¬å°æ–¼å„ªåŒ–é›»å» ç‡Ÿé‹ã€èƒ½æºèª¿åº¦èˆ‡ç¶­è­·è¦åŠƒå…·æœ‰å¯¦å‹™é‡è¦æ€§ã€‚

å°ˆæ¡ˆèšç„¦æ–¼å››å€‹ä¸»è¦é¢å‘ï¼š

1. å»ºæ¨¡æ–¹æ³•
2. æ¨¡å‹å»ºç«‹
3. æ¨¡å‹è©•ä¼°
4. æ¨¡å‹è§£é‡‹

---

### 2. å»ºæ¨¡æ–¹æ³•

#### 2.1 å•é¡Œé¡å‹

- **ç›®æ¨™è®Šæ•¸**: PEï¼ˆæ·¨é›»åŠ›è¼¸å‡ºï¼‰ï¼Œå–®ä½ç‚º MWï¼ˆç™¾è¬ç“¦ç‰¹ï¼‰  
- **æ•¸å€¼ç¯„åœ**: 420.26 â€“ 495.76 MW  
- **å•é¡Œé¡å‹**: è¿´æ­¸ï¼ˆé æ¸¬é€£çºŒæ•¸å€¼ï¼‰

ğŸ“Š **[è¦–è¦ºåŒ–å ä½ç¬¦]**: è³‡æ–™é›†é è¦½ï¼Œé¡¯ç¤º PE æ¬„ä½èˆ‡æ•¸å€¼ç¯„åœ  
_ä¾†æº: `notebooks/power_plant_prediction.ipynb`_

#### 2.2 ç‰¹å¾µé¸æ“‡

ä½¿ç”¨å››å€‹ç’°å¢ƒæ„Ÿæ¸¬å™¨ç‰¹å¾µï¼š

| ç‰¹å¾µ | èªªæ˜ | ç¯„åœ | èˆ‡ PE çš„ç›¸é—œæ€§ |
|-----|------|------|---------------|
| AT | ç’°å¢ƒæº«åº¦ | 1.81 â€“ 37.11 Â°C | -0.948ï¼ˆå¼·è² ç›¸é—œï¼‰|
| V | æ’æ°£çœŸç©ºåº¦ | 25.36 â€“ 81.56 cm Hg | -0.870ï¼ˆå¼·è² ç›¸é—œï¼‰|
| AP | ç’°å¢ƒå£“åŠ› | 992.89 â€“ 1033.30 millibar | +0.518ï¼ˆä¸­åº¦æ­£ç›¸é—œï¼‰|
| RH | ç›¸å°æ¿•åº¦ | 25.56% â€“ 100.16% | +0.390ï¼ˆå¼±æ­£ç›¸é—œï¼‰|

**ç‰¹å¾µé¸æ“‡ç†ç”±**ï¼š

1. ç‰©ç†æ„ç¾©æ˜ç¢ºï¼šæ¯å€‹ç‰¹å¾µéƒ½åŸºæ–¼ç†±åŠ›å­¸åŸç†å½±éŸ¿é›»åŠ›è¼¸å‡º  
2. èˆ‡ç›®æ¨™è®Šæ•¸é¡¯è‘—ç›¸é—œ  
3. è³‡æ–™å“è³ªè‰¯å¥½ï¼š9568 ç­†è¨˜éŒ„ï¼Œç„¡ç¼ºå¤±å€¼æˆ–é‡è¤‡å€¼

ğŸ“Š **[è¦–è¦ºåŒ–å ä½ç¬¦]**: ç‰¹å¾µç›¸é—œæ€§çŸ©é™£æˆ–ç†±åœ–  
_ä¾†æº: `notebooks/power_plant_prediction.ipynb`_

#### 2.3 æ¼”ç®—æ³•é¸æ“‡

æ¯”è¼ƒå…©ç¨®æ¼”ç®—æ³•ï¼š

1. **Linear Regressionï¼ˆç·šæ€§è¿´æ­¸ï¼‰**  
   - åƒæ•¸åŒ–æ¼”ç®—æ³•ï¼Œå‡è¨­ç·šæ€§é—œä¿‚  
   - ç°¡å–®ã€å¿«é€Ÿã€æ˜“è§£é‡‹  
   - ä½œç‚ºåŸºæº–æ¨¡å‹ä½¿ç”¨

2. **Random Forest Regressorï¼ˆéš¨æ©Ÿæ£®æ—è¿´æ­¸ï¼‰**  
   - éåƒæ•¸åŒ–é›†æˆæ¼”ç®—æ³•ï¼ˆå¤šæ£µæ±ºç­–æ¨¹ï¼‰  
   - æ•æ‰éç·šæ€§é—œä¿‚èˆ‡ç‰¹å¾µäº¤äº’ä½œç”¨  
   - ä¸éœ€å‡è¨­è³‡æ–™åˆ†ä½ˆ

---

### 3. æ¨¡å‹å»ºç«‹

#### 3.1 è³‡æ–™åˆ†å‰²ç­–ç•¥

- **è³‡æ–™é›†å¤§å°**: 9568 ç­†è¨˜éŒ„  
- **åˆå§‹åˆ†å‰²**: 80% è¨“ç·´é›†ï¼ˆ~7654 ç­†ï¼‰ã€20% æ¸¬è©¦é›†ï¼ˆ~1914 ç­†ï¼‰  
- **åŸå‰‡**: æ¸¬è©¦é›†ä¿ç•™è‡³æœ€çµ‚è©•ä¼°ï¼Œé¿å…åå·®

ğŸ“Š **[è¦–è¦ºåŒ–å ä½ç¬¦]**: è³‡æ–™åˆ†å‰²ç¤ºæ„åœ–ï¼ˆ80/20 + 5-Fold CV èªªæ˜ï¼‰  
_ä¾†æº: `docs/presentation_script.md` æˆ–è‡ªè£½åœ–è¡¨_

#### 3.2 äº¤å‰é©—è­‰

- **æ–¹æ³•**: åœ¨è¨“ç·´é›†ä¸Šé€²è¡Œ 5-Fold äº¤å‰é©—è­‰  
- **ç›®çš„**:  
  - æœ€å¤§åŒ–è³‡æ–™ä½¿ç”¨  
  - ç²å¾—ç©©å¥çš„è©•ä¼°çµæœ  
  - é™ä½éæ“¬åˆé¢¨éšª

#### 3.3 æ¨¡å‹æ¯”è¼ƒ

- **è©•ä¼°æŒ‡æ¨™**: MAEï¼ˆå¹³å‡çµ•å°èª¤å·®ï¼‰  
- **Scikit-learn èªªæ˜**: `cross_val_score` ä½¿ç”¨ neg_mean_absolute_error ä»¥ç¬¦åˆã€Œæ•¸å€¼è¶Šé«˜è¶Šå¥½ã€çš„æ…£ä¾‹

**5-Fold CV çµæœ**ï¼š

| æ¨¡å‹ | å¹³å‡ MAE | æ¨™æº–å·® | 5-Fold ç¯„åœ |
|-----|----------|--------|-------------|
| Linear Regression | 3.63 MW | Â±0.06 | 3.56â€“3.71 MW |
| Random Forest | 2.48 MW | Â±0.07 | 2.35â€“2.55 MW |

**è§€å¯Ÿçµæœ**: Random Forest èª¤å·®é™ä½ 31.68%ï¼Œè¡¨ç¾ç©©å®š

ğŸ“Š **[è¦–è¦ºåŒ–å ä½ç¬¦]**: å…©æ¨¡å‹ CV MAE æ¯”è¼ƒé•·æ¢åœ–ï¼ˆå«èª¤å·®ç·šï¼‰  
_ä¾†æº: `notebooks/power_plant_prediction.ipynb`_

---

### 4. æ¨¡å‹è©•ä¼°

#### 4.1 è©•ä¼°æŒ‡æ¨™

| æŒ‡æ¨™ | MAE | RÂ² |
|-----|-----|----|
| æ„ç¾© | å¹³å‡é æ¸¬èª¤å·® | æ¨¡å‹è§£é‡‹çš„è®Šç•°æ¯”ä¾‹ |
| å–®ä½ | MW | ç„¡å–®ä½ï¼ˆ0-1ï¼‰|
| ç›®æ¨™ | è¶Šä½è¶Šå¥½ | è¶Šé«˜è¶Šå¥½ |
| ç¯„ä¾‹ | 2.33 MW å¹³å‡èª¤å·® | RÂ² = 0.96 |

- é¸æ“‡ MAEï¼šç›´è§€æ˜“æ‡‚ã€å°ç•°å¸¸å€¼ç©©å¥ã€ç¬¦åˆå¯¦å‹™éœ€æ±‚  
- åŒæ™‚å ±å‘Š RÂ²ï¼šæ¨™æº–åŒ–æ¯”è¼ƒ

#### 4.2 æ¸¬è©¦é›†çµæœ

- **æœ€ä½³æ¨¡å‹**: Random Forest  
- **æ¸¬è©¦é›† MAE**: 2.33 MW  
- **æ¸¬è©¦é›† RÂ²**: 0.9637  

**çµæœè§£è®€**ï¼š

1. å¹³å‡é æ¸¬èª¤å·® â‰ˆ è¼¸å‡ºç¯„åœçš„ 0.5%  
2. è§£é‡‹ 96.37% çš„é›»åŠ›è¼¸å‡ºè®Šç•°  
3. CV MAE æ¥è¿‘æ¸¬è©¦é›† MAE â†’ ç„¡éæ“¬åˆ  

**è¦–è¦ºåŒ–èªªæ˜**: å¯¦éš›å€¼ vs é æ¸¬å€¼æ•£ä½ˆåœ–é¡¯ç¤ºå¤šæ•¸é»ç·Šå¯†åˆ†ä½ˆåœ¨ y=x ç·šé™„è¿‘ï¼Œé¡¯ç¤ºé«˜æº–ç¢ºåº¦èˆ‡ç©©å®šæ€§

ğŸ“Š **[è¦–è¦ºåŒ–å ä½ç¬¦]**: æ¸¬è©¦é›†çš„å¯¦éš›å€¼ vs é æ¸¬å€¼æ•£ä½ˆåœ–  
_ä¾†æº: `notebooks/power_plant_prediction.ipynb`_

---

### 5. æ¨¡å‹è§£é‡‹

#### 5.1 ç‚ºä½• Random Forest è¡¨ç¾æ›´ä½³

1. æ•æ‰è¤‡é›œç†±åŠ›å­¸éç¨‹ä¸­çš„éç·šæ€§é—œä¿‚  
2. è™•ç†ç‰¹å¾µäº¤äº’ä½œç”¨ï¼ˆä¾‹å¦‚é«˜æº« + é«˜æ¿•åº¦æ•ˆæ‡‰ï¼‰  
3. é›†æˆæ–¹æ³•å¹³å‡ 100 æ£µæ±ºç­–æ¨¹ä»¥é™ä½æ•´é«”èª¤å·®

#### 5.2 å¯¦å‹™æ‡‰ç”¨

- **èƒ½æºèª¿åº¦**: æ ¹æ“šå¤©æ°£é å ±é æ¸¬è¼¸å‡º  
- **é‹ç¶­å„ªåŒ–**: é æ¸¬å€¼èˆ‡å¯¦éš›å€¼å·®ç•°å¯åµæ¸¬è¨­å‚™å•é¡Œ  
- **æˆæœ¬æ§åˆ¶**: æ”¹å–„ç‡ƒæ–™æ¡è³¼èˆ‡åº«å­˜ç®¡ç†

- æ¸¬è©¦é›† MAE 2.33 MW â†’ é”åˆ°å¯¦ç”¨ç²¾åº¦

#### 5.3 éæ“¬åˆé é˜²

- ç¨ç«‹æ¸¬è©¦é›†  
- 5-Fold CV ç¢ºä¿ç©©å¥è¡¨ç¾  
- CV èˆ‡æ¸¬è©¦é›† MAE ä¸€è‡´æ€§ç¢ºèªæ³›åŒ–èƒ½åŠ›

---

### 6. æœªä¾†æ”¹é€²æ–¹å‘

1. æ¢ç´¢å…¶ä»–æ¼”ç®—æ³•ï¼šGradient Boostingã€ç¥ç¶“ç¶²è·¯  
2. Random Forest è¶…åƒæ•¸èª¿æ•´  
3. ç´å…¥æ›´å¤šç‰¹å¾µï¼šæ­·å²ç™¼é›»æ•¸æ“šã€è¨­å‚™é‹è½‰æ™‚é–“

---

### 7. çµè«–

æœ¬å°ˆæ¡ˆå±•ç¤ºäº†æˆåŠŸçš„é›»å» èƒ½æºé æ¸¬æ¨¡å‹ï¼š

- æ­£ç¢ºçš„å•é¡Œè­˜åˆ¥ï¼ˆè¿´æ­¸ï¼‰èˆ‡æ¼”ç®—æ³•é¸æ“‡  
- åš´è¬¹çš„é©—è­‰ï¼ˆ5-Fold CV + ç¨ç«‹æ¸¬è©¦é›†ï¼‰  
- å¯¦ç”¨çš„æ€§èƒ½ï¼ˆæ¸¬è©¦é›† MAE 2.33 MWï¼Œç›¸å°èª¤å·® 0.5%ï¼‰ï¼Œé©ç”¨æ–¼å¯¦éš›èƒ½æºèª¿åº¦èˆ‡ç‡Ÿé‹å„ªåŒ–
