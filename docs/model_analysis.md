# 模型方法論詳細說明

## 1. 問題類型判斷：為何是迴歸問題？

### 迴歸 vs 分類的區別

**分類問題 (Classification)**：預測的目標是**離散的類別標籤**。
- 例如：預測電子郵件是否為垃圾郵件（是/否）
- 例如：預測客戶會購買哪種產品（A類/B類/C類）

**迴歸問題 (Regression)**：預測的目標是**連續的數值**。
- 例如：預測房價（$100,000 到 $1,000,000）
- 例如：預測溫度（-10°C 到 40°C）

### 本專案的判斷

在本專案中，我們要預測的目標變數是 **PE (Net Hourly Electrical Energy Output)**：
- **資料類型**：連續數值
- **數值範圍**：420.26 ~ 495.76 **MW (MegaWatt 百萬瓦特)**
- **特性**：可以取任何在此範圍內的數值，例如 445.23 MW、478.91 MW 等
- **單位說明**：因為目標變數 PE 的單位是 MW，所以預測誤差 MAE 的單位也是 MW

**結論**：由於目標變數 PE 是一個連續的數值變數，而非離散的類別，因此這是一個**迴歸問題（Regression Problem）**。

---

## 2. 特徵選擇：為何使用這四個特徵？

### 選用的特徵

本專案使用所有四個環境感測器特徵：

1. **AT (Ambient Temperature)** - 環境溫度 (1.81°C ~ 37.11°C)
2. **V (Exhaust Vacuum)** - 排氣真空度 (25.36 ~ 81.56 cm Hg)
3. **AP (Ambient Pressure)** - 環境壓力 (992.89 ~ 1033.30 millibar)
4. **RH (Relative Humidity)** - 相對濕度 (25.56% ~ 100.16%)

### 選擇理由

#### 2.1 物理意義明確
這些特徵都是實際的環境感測器數據，直接影響發電廠的運作效率：
- **環境溫度**：影響冷卻系統效率和熱力循環
- **排氣真空度**：反映蒸汽渦輪機的效率
- **環境壓力**：影響空氣密度和燃燒效率
- **相對濕度**：影響冷卻系統性能

#### 2.2 與目標變數的相關性
從相關性分析可以看出，所有特徵都與 PE（電力輸出）有顯著相關：
- **AT（溫度）**：負相關最強（溫度越高，輸出越低）
- **V（真空度）**：負相關（真空度越大，輸出越低）
- **AP（壓力）**：正相關（壓力越高，輸出越高）
- **RH（濕度）**：負相關（濕度越高，輸出越低）

#### 2.3 資料品質良好
- 無缺失值
- 數值範圍合理
- 無明顯異常值

**結論**：四個特徵都具有實務意義且與目標變數相關，因此全部納入模型。

---

## 3. 演算法選擇：為何選這兩種方法？

### 3.1 Linear Regression（線性迴歸）

#### 特性
- **參數化演算法（Parametric Algorithm）**
- 假設特徵與目標變數之間存在**線性關係**
- 公式：PE = β₀ + β₁×AT + β₂×V + β₃×AP + β₄×RH

#### 選擇理由
1. **作為基準模型（Baseline Model）**：簡單且易於解釋，適合作為比較的基準
2. **運算效率高**：訓練速度快，適合快速驗證
3. **可解釋性強**：每個特徵的係數可以直接解釋其對目標的影響
4. **參數少**：不易過擬合（overfitting）

#### 適用情境
- 當特徵與目標之間的關係較為線性時
- 當需要快速建立初步模型時
- 當需要模型具有高可解釋性時

### 3.2 Random Forest Regressor（隨機森林迴歸）

#### 特性
- **非參數化集成演算法（Non-parametric Ensemble Algorithm）**
- 由多棵決策樹組成，透過投票或平均來預測
- 不需要假設資料的分佈形式

#### 選擇理由
1. **處理非線性關係**：能自動捕捉特徵之間的複雜交互作用
2. **抗過擬合能力強**：透過集成多棵樹來降低過擬合風險
3. **對特徵尺度不敏感**：不需要標準化或正規化
4. **提供特徵重要性**：可以評估哪些特徵對預測最重要

#### 適用情境
- 當特徵與目標之間的關係較為複雜、非線性時
- 當特徵之間可能存在交互作用時
- 當資料量足夠大（本專案有 9568 筆）時

### 3.3 為何比較這兩種演算法？

| 特性 | Linear Regression | Random Forest |
|------|-------------------|---------------|
| 模型類型 | 參數化 | 非參數化 |
| 複雜度 | 簡單 | 複雜 |
| 訓練速度 | 快 | 較慢 |
| 處理非線性 | 弱 | 強 |
| 過擬合風險 | 低 | 中（透過集成降低） |
| 可解釋性 | 高 | 中 |

**結論**：透過比較**簡單的參數化模型**與**複雜的非參數化模型**，可以評估資料的複雜度，並選擇最適合的預測方法。

---

## 4. 評估指標：為何選擇 MAE？

### MAE (Mean Absolute Error) 的定義

$$\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

其中：
- $y_i$ 是實際值
- $\hat{y}_i$ 是預測值
- $n$ 是樣本數量

### 選擇 MAE 的理由

#### 4.1 直觀易懂
- MAE 的單位與目標變數相同（MW）
- 可以直接解讀：「平均預測誤差為 X MW」
- 對於非技術背景的利害關係人更容易理解

#### 4.2 對異常值較穩健（Robust to Outliers）
- MAE 使用絕對值，不會過度放大大誤差的影響
- 相比之下，MSE/RMSE 使用平方，會過度懲罰極端誤差

#### 4.3 反映實務需求
在電廠管理中，我們關心的是：
- 「平均來說，我們的預測會偏離實際值多少？」
- MAE 直接回答這個問題

### MAE vs 其他指標

| 指標 | 優點 | 缺點 |
|------|------|------|
| **MAE** | 直觀、對異常值穩健 | 數學上不可微分於零點 |
| **MSE** | 數學性質好、可微分 | 單位不直觀（MW²） |
| **RMSE** | 單位與目標相同 | 對異常值敏感 |
| **R²** | 顯示解釋比例 | 不反映實際誤差大小 |

**結論**：MAE 是最適合本專案的主要評估指標，但也會輔助報告 R² 來說明模型的解釋能力。

---

## 5. 驗證策略：為何使用 5-Fold Cross-Validation？

### 5.1 資料分割策略

#### Initial Split（初始分割）
- **訓練集**：80%（約 7654 筆）
- **測試集**：20%（約 1914 筆）

**目的**：
- 訓練集用於模型訓練和比較
- 測試集**完全保留**，僅在最後用於評估最終模型
- 確保測試結果**無偏且可靠**

#### K-Fold Cross-Validation（K 折交叉驗證）
- 將訓練集分成 **K=5** 份
- 每次用 4 份訓練、1 份驗證
- 重複 5 次，確保每份資料都被用作驗證集一次

### 5.2 為何選擇 5-Fold？

#### 優點
1. **充分利用訓練資料**：每次使用 80% 的訓練集（約 6123 筆）來訓練
2. **評估更穩健**：透過 5 次驗證的平均結果，降低單次分割的隨機性
3. **計算成本適中**：相比 10-Fold，訓練次數較少但仍有足夠的驗證可靠度
4. **適合中型資料集**：對於 7654 筆訓練資料，5-Fold 是常見且有效的選擇

#### 與其他方法的比較

| 方法 | 訓練資料使用率 | 可靠度 | 計算成本 |
|------|---------------|--------|----------|
| **Hold-out (70/30)** | 70% | 低（單次分割） | 低 |
| **3-Fold CV** | 66.7% | 中 | 低 |
| **5-Fold CV** | 80% | 高 | 中 |
| **10-Fold CV** | 90% | 很高 | 高 |
| **LOOCV** | 99.9% | 最高 | 極高 |

**結論**：5-Fold CV 在資料利用率、可靠度和計算成本之間取得最佳平衡。

---

## 6. 如何避免過擬合（Overfitting）？

### 6.1 什麼是過擬合？

**過擬合**：模型在訓練資料上表現很好，但在未見過的測試資料上表現很差。

### 6.2 本專案的防範措施

#### 措施 1：保留獨立測試集
- 測試集**從未被用於模型訓練或選擇**
- 確保最終評估結果**無偏**

#### 措施 2：使用交叉驗證
- 5-Fold CV 評估模型在不同資料子集上的**泛化能力**
- 避免模型只是「記住」特定的驗證集

#### 措施 3：比較簡單與複雜模型
- Linear Regression：低複雜度，低過擬合風險
- Random Forest：雖較複雜，但透過集成降低過擬合

#### 措施 4：Random Forest 的內建機制
- **Bootstrap Aggregating (Bagging)**：每棵樹用不同的資料子集訓練
- **隨機特徵選擇**：每次分裂只考慮部分特徵
- **n_estimators=100**：集成 100 棵樹，降低單棵樹的過擬合

### 6.3 如何判斷是否過擬合？

觀察指標：
- **訓練集 MAE << 驗證集 MAE**：可能過擬合
- **交叉驗證 MAE ≈ 測試集 MAE**：泛化能力良好

---

## 7. 模型選擇流程總結

```
原始資料 (9568 筆)
    ↓
初始分割 (80/20)
    ↓
訓練集 (80%)              測試集 (20%) ← 完全保留
    ↓
5-Fold 交叉驗證
    ↓
比較 Linear Regression vs Random Forest
    ↓
選擇平均 MAE 最低的模型
    ↓
在完整訓練集上重新訓練
    ↓
在測試集上計算最終 MAE 和 R²
    ↓
報告最終結果
```

---

## 8. 結論

### 為何這個方法論是合理的？

1. **問題定義正確**：識別為迴歸問題，選擇適當的演算法和指標
2. **特徵選擇有理**：所有特徵都具有物理意義且與目標相關
3. **演算法多樣性**：比較參數化與非參數化方法，評估資料複雜度
4. **評估指標適當**：MAE 直觀且符合實務需求
5. **驗證策略嚴謹**：使用交叉驗證和獨立測試集，確保結果可靠
6. **避免過擬合**：透過多種機制確保模型的泛化能力

這個方法論遵循**機器學習的最佳實務（Best Practices）**，確保模型的可靠性和實用性。
